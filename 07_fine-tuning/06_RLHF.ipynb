{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b69f47",
   "metadata": {},
   "source": [
    "# 사용자 선호에 맞는 시 창작 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9725a",
   "metadata": {},
   "source": [
    "### 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bfaa89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (25.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ec7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (2.11.3)\n",
      "Requirement already satisfied: openai in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (1.76.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pydantic) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install typing_extensions pydantic openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515293c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: peft in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: trl in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (0.45.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: rich in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from torch>=1.13.0->peft) (75.8.0)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from sympy!=1.13.2,>=1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\playdata\\anaconda3\\envs\\ollama_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets transformers peft trl bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7025afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq, BitsAndBytesConfig, GenerationConfig, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import ORPOTrainer, ORPOConfig, AutoModelForCausalLMWithValueHead\n",
    "from trl.trainer.utils import DPODataCollatorWithPadding\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f648579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"           # wandb 비활성화\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # 병렬 토크나이저 경고 방지\n",
    "\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"  # GPU 설정 변수\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3abd7c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a4243",
   "metadata": {},
   "source": [
    "## Q-LoRA 파인튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0e0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 Dataset 변환\n",
    "dataset_path = \"./korean_poetry_dataset.json\"\n",
    "\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    poem_data = json.load(f)\n",
    "\n",
    "preprocessed_data = [{\"topic\": item[\"text\"][\"topic\"], \"poem\": item[\"text\"][\"poem\"]} for item in poem_data]\n",
    "\n",
    "train_dataset = Dataset.from_list(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94705db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer 로드\n",
    "model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c74887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수 (토큰화 + labels 추가)\n",
    "def preprocess_text(sample):\n",
    "    input_texts = [f\"주제: {t}\\n시: {p}\" for t, p in zip(sample[\"topic\"], sample[\"poem\"])]\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "                        input_texts, \n",
    "                        padding=\"max_length\",\n",
    "                        max_length=512,\n",
    "                        truncation=True\n",
    "                    )\n",
    "\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    model_inputs[\"labels\"] = [\n",
    "        [(l if l != pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520656bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2600/2600 [00:00<00:00, 2745.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 변환\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess_text,\n",
    "    batched=True,\n",
    "    remove_columns=[\"topic\", \"poem\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c603d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 콜레이터\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483454d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRAM 최적화를 위한 4-bit 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17815868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ecde449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양자화 모델 훈련을 위한 준비\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea042608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 적용\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "model.train()   # 모델 학습 모드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2b6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./q_lora_poem\",\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    optim=\"adamw_bnb_8bit\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e417a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9fee3",
   "metadata": {},
   "source": [
    "### 시 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b07f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파인튜닝된 모델로 시 생성\n",
    "qlora_checkpoint = \"./q_lora_poem/checkpoint-243\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(qlora_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "generate_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a037bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"바람\", \"비\", \"노을\", \"달빛\", \"안개\", \"사랑\", \"이별\", \"운명\", \"기다림\", \"후회\", \"추억\", \"시간\", \"청춘\", \"변화\", \"마지막 순간\", \"군중\", \"밤거리\", \"버스\", \"인생\", \"빌딩\", \"사람들\", \"거짓말\", \"욕망\", \"돈\", \"권력\", \"비밀\", \"죽음\", \"희망\", \"동물\", \"자연\", \"도시\", \"바다\", \"산\", \"하늘\", \"별\", \"꽃\", \"나무\", \"강\", \"바위\", \"흙\", \"눈\", \"빗방울\", \"눈물\", \"웃음\"]\n",
    "\n",
    "eval_file = 'rlhf_evaluation_data.json'\n",
    "\n",
    "try:\n",
    "    with open(eval_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        eval_dataset = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    eval_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a876e3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시 생성을 위한 변수 설정\n",
    "num_batches = 5\n",
    "batch_size = 20\n",
    "total_samples = num_batches * batch_size \n",
    "generated_samples = len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07fac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시 생성 함수\n",
    "def generate_poem_batch():\n",
    "    batch_data = []\n",
    "\n",
    "    with tqdm(total=batch_size, desc=\"<시 생성 중>\", leave=False) as t:\n",
    "        for _ in range(batch_size):\n",
    "            topic = random.choice(topics)\n",
    "            input_text = f\"주제: {topic}\\n시:\"\n",
    "\n",
    "            start_time = time.time()\n",
    "            poem = generate_pipeline(\n",
    "                                        input_text,\n",
    "                                        max_new_tokens=100,\n",
    "                                        temperature=0.8,\n",
    "                                        top_p=0.9\n",
    "                                    )[0]['generated_text']\n",
    "            end_time = time.time()\n",
    "\n",
    "            gen_time = end_time - start_time\n",
    "            batch_data.append({\n",
    "                \"topic\": topic,\n",
    "                \"poem\": poem,\n",
    "                \"selected\": None\n",
    "            })\n",
    "\n",
    "            # tqdm\n",
    "            t.update(1)\n",
    "\n",
    "            global generated_samples\n",
    "            generated_samples += 1\n",
    "            complete_rate = (generated_samples / total_samples) * 100\n",
    "            remaining_time = ((total_samples - generated_samples) * gen_time) / 60\n",
    "\n",
    "            print(f'\\n{generated_samples}/{total_samples}개 완료 ({complete_rate:.2f}%)')\n",
    "            print(f'- 예상 남은 시간 : {remaining_time:.1f}분')\n",
    "            print('-' * 50)\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22466c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시 저장 및 json 저장\n",
    "for _ in tqdm(range(num_batches), desc=\"<전체 진행 상황>\", position=0):\n",
    "    eval_dataset.extend(generate_poem_batch())\n",
    "\n",
    "    with open(eval_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(eval_dataset, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d821ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab85c4b",
   "metadata": {},
   "source": [
    "### Reward model\n",
    "- 앞서 생성한 시에 대해서 selected=true로 수정해 피드백 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee553ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 시+선호도 파일 로드\n",
    "with open(eval_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    evaluation_data = json.load(f)\n",
    "\n",
    "reward_data = [\n",
    "    {'text_a': f'주제: {item[\"topic\"]}', 'text_b': item['poem']}\n",
    "    for item in evaluation_data if item['selected']\n",
    "]\n",
    "\n",
    "reward_dataset = Dataset.from_list(reward_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수 (배치 데이터 처리)\n",
    "def preprocess_reward_data(sample):\n",
    "\n",
    "    model_inputs = tokenizer(\n",
    "                        sample[\"text_a\"],\n",
    "                        text_pair=sample[\"text_b\"],\n",
    "                        padding=\"max_length\",\n",
    "                        max_length=512,\n",
    "                        truncation=True\n",
    "                    )\n",
    "\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    model_inputs[\"labels\"] = [\n",
    "        [(l if l != pad_token_id else -100) for l in label] for label in model_inputs[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "reward_dataset = reward_dataset.map(\n",
    "    preprocess_reward_data,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text_a\", \"text_b\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56091299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VRAM 최적화를 위한 4-bit 설정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 생성\n",
    "reward_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "\n",
    "reward_model = prepare_model_for_kbit_training(reward_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 적용\n",
    "reward_model = get_peft_model(reward_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 설정\n",
    "reward_training_args = TrainingArguments(\n",
    "    output_dir=\"./reward_model\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "reward_trainer = Trainer(\n",
    "    model=reward_model,\n",
    "    args=reward_training_args,\n",
    "    train_dataset=reward_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0c2bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a1c5c",
   "metadata": {},
   "source": [
    "### RLHF (ORPO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
