{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567ec48f-e183-45a1-b45f-131ebadc6ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-1.76.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.9/352.9 kB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, safetensors, regex, jiter, h11, fsspec, annotated-types, typing-inspection, pydantic-core, huggingface-hub, httpcore, tokenizers, pydantic, httpx, accelerate, transformers, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-1.6.0 annotated-types-0.7.0 fsspec-2025.3.2 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.30.2 jiter-0.9.0 openai-1.76.0 pydantic-2.11.3 pydantic-core-2.33.1 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 typing-extensions-4.13.2 typing-inspection-0.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers openai accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76219ea0-cbe5-4339-8e89-445f6226580c",
   "metadata": {},
   "source": [
    "### sLLM-LLM 응답 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e3cfab-fc40-4f58-89d4-a998f57ddad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the theory of relativity in simple terms.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7b20d-836c-4ad6-abd2-93d35e346d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e78de0-c8d9-4a83-8609-1433d2442fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d434832d9e1455eaef36bf57643692a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119818e4d6234d0db9b1abfdf13ec693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ac6914cfb441838a9f09bce0586548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c1eb05d07f4291a7c363ad60e9b3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c629de0b65b147e5b5732a67b83a3857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe50ec2858c147a2a8d8001de08732bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508ca3241ab644d78f8966f8fdc2f811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136c09480a43421ba29f794eaf6a5e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76feb499a89d477eb07881bd63e36dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35eebb3c860943a9a123275a85566436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49254b7c924a4a27b6fe734d10dba8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "sllm_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(sllm_model_name, token=hf_token)\n",
    "sllm = AutoModelForCausalLM.from_pretrained(sllm_model_name, token=hf_token, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f26f9d8-3015-436a-bc69-c1e55685dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(sllm.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03dbef2c-53c1-4efe-b1f8-13e9a3f8b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = sllm.generate(**inputs, max_length=500)\n",
    "sllm_res = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a320695-ee38-4dd0-a0af-c2ccc8843850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "gpt_res = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eab5619-2495-49d0-a34b-b7836f1b5641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, developed by Albert Einstein, consists of two main parts: special relativity and general relativity. Here's a simple explanation of each:\n",
      "\n",
      "### Special Relativity\n",
      "1. **Speed of Light**: This theory states that the speed of light in a vacuum is constant (about 186,282 miles per second, or 299,792 kilometers per second) and the same for everyone, no matter how fast they are moving.\n",
      "   \n",
      "2. **Time Dilation**: Time can pass at different rates depending on how fast you're moving. If you travel close to the speed of light, time goes more slowly for you compared to someone who is standing still. This means if an astronaut travels at near-light speed and returns, they might find less time has passed for them compared to people on Earth.\n",
      "\n",
      "3. **Length Contraction**: Objects appear shorter in the direction they are moving when they are traveling close to the speed of light. So, a spaceship moving quickly would look compressed in the direction it's traveling to an outside observer.\n",
      "\n",
      "4. **Mass-Energy Equivalence**: This famous equation, \\(E = mc^2\\), means that energy (E) and mass (m) are interchangeable. A small amount of mass can be converted into a large amount of energy, explaining phenomena like nuclear reactions.\n",
      "\n",
      "### General Relativity\n",
      "1. **Gravity as Curvature**: Instead of thinking of gravity as a force, Einstein proposed that massive objects (like Earth) warp the space around them. Imagine placing a heavy ball on a trampoline; it creates a dip in the fabric of the trampoline. Smaller objects move along curved paths in this warped space, which we perceive as gravity.\n",
      "\n",
      "2. **Time and Gravity**: Time also passes more slowly in stronger gravitational fields. For example, a clock closer to a massive object (like Earth) ticks more slowly than a clock further away. This effect is known as gravitational time dilation.\n",
      "\n",
      "In summary, Einstein's theory of relativity teaches us that space and time are interconnected and that our understanding of these concepts changes depending on our relative motion and the influence of gravity. Overall, it shows that the universe operates in ways that can be quite different from our everyday experiences.\n"
     ]
    }
   ],
   "source": [
    "print(gpt_res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ee1423-fe1d-4139-bab7-cc7dd2940880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the theory of relativity in simple terms.\n",
      "Why is the speed of light constant in a vacuum?\n",
      "Explain why the speed of light is constant in a vacuum.\n",
      "What is the formula for calculating the speed of light in a vacuum?\n",
      "The formula for calculating the speed of light in a vacuum is c = 299,792,458 meters per second.\n",
      "What is the speed of light in a vacuum?\n",
      "The speed of light in a vacuum is 299,792,458 meters per second.\n",
      "What is the speed of light in a vacuum in meters per second?\n",
      "The speed of light in a vacuum is 299,792,458 meters per second.\n",
      "What is the speed of light in a vacuum in feet per second?\n",
      "The speed of light in a vacuum is 186,282 miles per second.\n",
      "What is the speed of light in a vacuum in kilometers per second?\n",
      "The speed of light in a vacuum is 670,616,629 miles per second.\n",
      "What is the speed of light in a vacuum in miles per hour?\n",
      "The speed of light in a vacuum is 186,282 miles per hour.\n",
      "What is the speed of light in a vacuum in kilometers per hour?\n",
      "The speed of light in a vacuum is 186,282 kilometers per hour.\n",
      "What is the speed of light in a vacuum in miles per minute?\n",
      "The speed of light in a vacuum is 186,282 miles per minute.\n",
      "What is the speed of light in a vacuum in kilometers per minute?\n",
      "The speed of light in a vacuum is 186,282 kilometers per minute.\n",
      "What is the speed of light in a vacuum in miles per second?\n",
      "The speed of light in a vacuum is 186,282 miles per second.\n",
      "What is the speed of light in a vacuum in kilometers per second?\n",
      "The speed of light in a vacuum is 186,2\n"
     ]
    }
   ],
   "source": [
    "print(sllm_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324b0be-90a0-4358-ac56-5f3bf16fbed5",
   "metadata": {},
   "source": [
    "### sLLM-LLM 속도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e0fdfe3-4400-41e7-a135-054606ffb531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33afcfcb51ee4de485ec0349407a60a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cfd818fc51478b9507e9faa27b275d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b86aa981314aad85f8d9e76d8ee7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cbec55117240b38752e88942bab929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bc92da5ea94dd0a9d1c3eb123c592d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbe3067fb3c46529db43eba3d194b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/6.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c201071edbe44145a75a4331acfa9642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17866e8ea4c94d149f303d002f2ef651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "llm_model_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "llm = AutoModelForCausalLM.from_pretrained(llm_model_name, token=hf_token, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6010df52-7d39-4eec-b9e3-15846086716b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the benefits of using LLM.\n",
      "An LLM is a master’s degree that focuses on legal studies. It is a postgraduate degree that is often pursued by students who wish to specialize in a particular area of law.\n",
      "The benefits of using an LLM include:\n",
      "1. An LLM can help you to gain a better understanding of the law and how it operates.\n",
      "2. An LLM can help you to develop your research skills.\n",
      "3. An LLM can help you to improve your writing skills.\n",
      "4. An LLM can help you to improve your oral presentation skills.\n",
      "5. An LLM can help you to improve your critical thinking skills.\n",
      "6. An LLM can help you to improve your problem-solving skills.\n",
      "7. An LLM can help you to improve your time management skills.\n",
      "8. An LLM can help you to improve your teamwork skills.\n",
      "9. An LLM can help you to improve your leadership skills.\n",
      "10. An LLM can help you to improve your communication skills.\n",
      "11. An LLM can help you to improve your networking skills.\n",
      "12. An LLM can help you to improve your professionalism.\n",
      "13. An LLM can help you to improve your career prospects.\n",
      "14. An LLM can help you to improve your financial situation.\n",
      "15. An LLM can help you to improve your quality of life.\n",
      "16. An LLM can help you to improve your health.\n",
      "17. An LLM can help you to improve your relationships.\n",
      "18. An LLM can help you to improve your mental health.\n",
      "19. An LLM can help you to improve your physical health.\n",
      "20. An LLM can help you to improve your emotional health.\n",
      "21. An LLM can help you to improve your spiritual health.\n",
      "22. An LLM can help you to improve your social health.\n",
      "23. An LLM can help you to improve your intellectual health.\n",
      "24. An LLM can help you to improve your financial health.\n",
      "25. An LLM can help you to improve your physical health.\n",
      "26. An LLM can help you to improve your mental health.\n",
      "27. An LLM can help you to improve your\n",
      "시간: 11.24초\n",
      "Explain the benefits of using LLM.\n",
      "LLM is a language model that is trained on a large corpus of text data to generate human-like text. It can be used to generate text for a variety of purposes, such as writing articles, creating marketing materials, or generating product descriptions.\n",
      "LLM can generate text that is more accurate and natural-sounding than other text generation methods. It can also generate text that is more specific to a particular topic or niche, which can be useful for generating content that is tailored to a specific audience.\n",
      "LLM can be used to generate text for a variety of purposes, such as writing articles, creating marketing materials, or generating product descriptions. It can also be used to generate text for social media, such as generating tweets or posts for Twitter or Facebook.\n",
      "LLM can be used to generate text that is more accurate and natural-sounding than other text generation methods. It can also generate text that is more specific to a particular topic or niche, which can be useful for generating content that is tailored to a specific audience.\n",
      "LLM can be used to generate text for a variety of purposes, such as writing articles, creating marketing materials, or generating product descriptions. It can also be used to generate text for social media, such as generating tweets or posts for Twitter or Facebook.\n",
      "LLM can be used to generate text that is more accurate and natural-sounding than other text generation methods. It can also generate text that is more specific to a particular topic or niche, which can be useful for generating content that is tailored to a specific audience.\n",
      "LLM can be used to generate text that is more accurate and natural-sounding than other text generation methods. It can also generate text that is more specific to a particular topic or niche, which can be useful for generating content that is tailored to a specific audience.\n",
      "LLM can be used to generate text for a variety of purposes, such as writing articles, creating marketing materials, or generating product descriptions. It can also be used to generate text for social media, such as generating tweets or posts for Twitter or Facebook.\n",
      "LLM can be used to generate text that is more accurate and natural-sounding than other text generation methods. It can also generate text that is more specific to a particular topic or niche, which can be useful for\n",
      "시간: 110.95초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "models = [sllm, llm]\n",
    "prompt = \"Explain the benefits of using LLM.\"\n",
    "\n",
    "for model in models:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    outputs = model.generate(**inputs, max_length=500)\n",
    "    end_time = time.time()\n",
    "\n",
    "    model_res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(model_res)\n",
    "    print(f\"시간: {end_time - start_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448c884-29f4-4a70-8022-b0c026aab7cb",
   "metadata": {},
   "source": [
    "### 응답 유지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9e915d5-2515-45dd-be5c-3bc0c9c56ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am planning a trip to Japan. What are the best cities to visit?\n",
      "I am planning a trip to Japan. What are the best cities to visit? I am planning a trip to Japan. What are the best cities to visit? I am planning a trip to Japan. What are the best cities to visit?\n",
      "Japan is a country of many wonders. It is home to the world’s tallest building, the most populated city, and the most expensive hotel. There are so many places to explore in Japan, but if you’re looking for something unique, you should definitely check out these cities.\n",
      "Tokyo is one of the most popular tourist destinations in Japan. It is home to many famous landmarks and attractions, including the Tokyo Tower, Tokyo Disneyland, and Tokyo DisneySea. Tokyo is also known for its shopping and nightlife.\n",
      "Osaka is another popular tourist destination in Japan. It is home to many famous landmarks and attractions, including Osaka Castle, Osaka Castle Park, and Universal Studios Japan. Osaka is also known for its shopping and nightlife.\n",
      "Nagoya is another popular tourist destination in Japan. It is home to many famous landmarks and attractions, including Nagoya Castle, Nagoya Castle Park, and Nagoya Aquarium. Nagoya is also known for its shopping and nightlife.\n",
      "Kyoto is another popular tourist destination in Japan. It is home to many famous landmarks and attractions, including Kyoto Imperial Palace, Kiyomizu Temple, and Fushimi Inari Shrine. Kyoto is also known for its shopping and nightlife.\n",
      "Hiroshima is another popular tourist destination in Japan. It is home to many famous landmarks and attractions, including Hiroshima Peace Memorial Museum, Hiroshima Peace Memorial Park, and Hiroshima Castle. Hiroshima is also known for its shopping and nightlife.\n",
      "Nara is another popular tourist destination in Japan. It is home to many famous landmarks and attractions, including Nara Deer Park, Nara Park, and Nara Castle. Nara is also known for its shopping and nightlife.\n",
      "Yokohama is another popular tourist destination in Japan. It is home to many famous landmarks and attractions, including\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"I am planning a trip to Japan. What are the best cities to visit?\"\n",
    "\n",
    "inputs1 = tokenizer(prompt1, return_tensors=\"pt\").to(sllm.device)\n",
    "outputs1 = sllm.generate(**inputs1, max_length=500)\n",
    "response1 = tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0da23289-8225-40c6-bdc4-7f8854228b04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What local foods should I try in those cities?\n",
      "I have been asked this question many times by my friends who are traveling to a new city and want to know what local foods to try. I thought I’d share the answers here for everyone.\n",
      "If you are traveling to a new city, I recommend using the following sites to find out what local foods to try:\n",
      "Eat Like a Local – this is a great site to find out what local foods to try in a new city.\n",
      "Trip Advisor – you can find reviews of restaurants and what foods to try on this site.\n",
      "Trip Savvy – this is another great site to find out what local foods to try in a new city.\n",
      "If you are traveling to a new city, I recommend using the following sites to find out what local foods to try: Eat Like a Local – this is a great site to find out what local foods to try in a new city. Trip Advisor – you can find reviews of restaurants and what foods to try on this site. Trip Savvy – this is another great site to find out what local foods to try in a new city.\n",
      "What are some of the best local foods to try in those cities?\n",
      "There are many local foods to try in those cities. Some of the best local foods to try in those cities include:\n",
      "Fish and Chips – this is a traditional British dish that is very popular in London.\n",
      "Curry – this is a traditional Indian dish that is very popular in London.\n",
      "Ceviche – this is a traditional Peruvian dish that is very popular in Lima.\n",
      "Paella – this is a traditional Spanish dish that is very popular in Barcelona.\n",
      "Sushi – this is a traditional Japanese dish that is very popular in Tokyo.\n",
      "What are some of the best local foods to try in those cities? There are many local foods to try in those cities. Some of the best local foods to try in those cities include: Fish and Chips – this is a traditional British dish that is very popular in London. Curry – this is a traditional Indian dish that is very popular in London. Ceviche – this is a traditional Peruvian dish that is very popular in Lima. Paella – this is a traditional Spanish\n"
     ]
    }
   ],
   "source": [
    "prompt2 = \"What local foods should I try in those cities?\"\n",
    "\n",
    "inputs2 = tokenizer(prompt2, return_tensors=\"pt\").to(sllm.device)\n",
    "outputs2 = sllm.generate(**inputs2, max_length=500)\n",
    "response2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d75ac-9a52-41de-9330-6b201a924795",
   "metadata": {},
   "source": [
    "### 다국어 처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c45ab761-fc86-4371-bfbb-d37c96058fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4165153534f547d1bf6a62a10a75417a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "multilingual_model = pipeline(\"text-generation\", model=\"meta-llama/Llama-2-7b-hf\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3a3ef52-9d21-40b1-b96a-bd839de53bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== English ===\n",
      "Please translate 'Hello, how are you' into French.\n",
      "Please translate 'I'm fine, thank you' into French.\n",
      "Please translate 'How are you?' into French.\n",
      "Please translate 'How are you doing?' into French.\n",
      "Please translate 'I'm doing well, thank you' into French.\n",
      "Please translate 'I'm fine' into French.\n",
      "Please translate 'I'm good' into French.\n",
      "Please translate 'I'm okay'\n",
      "\n",
      "=== Korean ===\n",
      "안녕하세요. 오늘 날씨가 어때요? 눈이 내리고 땀이 치워요. 오늘 날씨가 따뜻하게 되면 좋을것 같아요. 밤이 �\n",
      "\n",
      "=== Japanese ===\n",
      "こんにちは。今日の天気はどうですか？\n",
      "おはようございます。今日の天気はどうですか？\n",
      "こんにちは。今日の天気はどうですか？\n",
      "こんにちは。今日の天気はどうですか？\n",
      "こんにちは。今日の天気はどうです\n"
     ]
    }
   ],
   "source": [
    "prompts = {\n",
    "    \"English\": \"Please translate 'Hello, how are you' into French\",\n",
    "    \"Korean\": \"안녕하세요. 오늘 날씨가 어때요?\",\n",
    "    \"Japanese\": \"こんにちは。今日の天気はどうですか？\"\n",
    "}\n",
    "\n",
    "for lang, prompt in prompts.items():\n",
    "    response = multilingual_model(prompt, max_length=100)\n",
    "    print(f\"\\n=== {lang} ===\")\n",
    "    print(response[0][\"generated_text\"])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
